{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "final fig (5) 100,1000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9EL48TFOnMu"
      },
      "source": [
        "# importing libs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda,Dense, GaussianNoise\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam,SGD\n",
        "import random as rn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlcPUlP5OnM2",
        "outputId": "c2b6ff78-93bc-4547-f789-7afccad7634b"
      },
      "source": [
        "# defining parameters\n",
        "M = 256\n",
        "Mmod= 16\n",
        "R = 1/2\n",
        "k = int(np.log2(M))\n",
        "kmod= int(np.log2(Mmod))\n",
        "n_channel = int(k/R)\n",
        "n= int(n_channel/kmod)\n",
        "\n",
        "print ('M:',M,'k:',k,'n_coded:',n_channel,'n:',n,'R:',R,'M_mod:',Mmod)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M: 256 k: 8 n_coded: 16 n: 4 R: 0.5 M_mod: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tEDp_PAaOnM4"
      },
      "source": [
        "#generating data of size N\n",
        "N = 1000000\n",
        "label = np.random.randint(M,size=N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2PqY1nPPOnM4"
      },
      "source": [
        "data = []\n",
        "for i in label:\n",
        "    temp=bin(i)[2:].zfill(k)\n",
        "    temp=np.array([float(d) for d in temp])\n",
        "    data.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai4PgnkUOnM4",
        "outputId": "b8624686-de68-48c8-aa6b-c5204170339e"
      },
      "source": [
        "data = np.array(data)\n",
        "print (data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000000, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aht0iPJmOnM5",
        "outputId": "0e70d552-71fb-4ef6-fecd-81787867b665"
      },
      "source": [
        "temp_check = [17,23,45,67,89,96,72,250,350]\n",
        "for i in temp_check:\n",
        "    print(label[i],data[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22 [0. 0. 0. 1. 0. 1. 1. 0.]\n",
            "67 [0. 1. 0. 0. 0. 0. 1. 1.]\n",
            "142 [1. 0. 0. 0. 1. 1. 1. 0.]\n",
            "8 [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "146 [1. 0. 0. 1. 0. 0. 1. 0.]\n",
            "35 [0. 0. 1. 0. 0. 0. 1. 1.]\n",
            "104 [0. 1. 1. 0. 1. 0. 0. 0.]\n",
            "156 [1. 0. 0. 1. 1. 1. 0. 0.]\n",
            "167 [1. 0. 1. 0. 0. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAXSi-qqMdrv"
      },
      "source": [
        "lr=0.001\r\n",
        "Eb_N0db=5\r\n",
        "Eb_N0=10.0**(Eb_N0db/10.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMEnHWAOnM5"
      },
      "source": [
        "# defining autoencoder and it's layer\n",
        "input_signal = Input(shape=(k,))\n",
        "encoded = Dense(n_channel, activation='relu')(input_signal)\n",
        "encoded1 = Dense(2*n, activation='relu')(encoded)\n",
        "encoded2 = Dense(2*n, activation='relu')(encoded1)\n",
        "encoded3 = Dense(2*n, activation='linear')(encoded2)\n",
        "encoded4 = Lambda(lambda x: np.sqrt(2*n)*K.l2_normalize(x,axis=1))(encoded3)\n",
        "\n",
        "encoded5 = GaussianNoise(np.sqrt(1/(2*R*kmod*Eb_N0)))(encoded4)\n",
        "\n",
        "decoded = Dense(2*n, activation='relu')(encoded5)\n",
        "decoded1 = Dense(n_channel, activation='linear')(decoded)\n",
        "decoded2 = Dense(k, activation='sigmoid')(decoded1)\n",
        "\n",
        "autoencoder = Model(input_signal, decoded2)\n",
        "adam = Adam(lr)\n",
        "autoencoder.compile(optimizer=adam, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zod3REkOnM6",
        "outputId": "e30217ad-ba6d-4f88-f37e-6cc4e6e74c73"
      },
      "source": [
        "print (autoencoder.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 136       \n",
            "=================================================================\n",
            "Total params: 776\n",
            "Trainable params: 776\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJw-5GCnOnM6",
        "scrolled": true,
        "outputId": "ec45941d-727f-4a44-ddba-a386ccd4dc93"
      },
      "source": [
        "autoencoder.fit(data, data,\n",
        "                epochs=100,\n",
        "                batch_size=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.4901\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1861\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1205\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1047\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1011\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0986\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0964\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0950\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0941\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0921\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0804\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0564\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0364\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0320\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0302\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0284\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0281\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0274\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0269\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0265\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0260\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0254\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0253\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0248\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0247\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0241\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0220\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0212\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0201\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0195\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0192\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0188\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0187\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0185\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0187\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0185\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0185\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0184\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0183\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0180\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0183\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0181\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0180\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0180\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0177\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0177\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0178\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0177\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0175\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0175\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0177\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0174\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0175\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0174\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0176\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0175\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0172\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0174\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0175\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0175\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0174\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0174\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0175\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0172\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0172\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0175\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0173\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0173\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0171\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0171\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0172\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0172\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0172\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0170\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0170\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0172\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0171\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0169\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0172\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0172\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f80ddb98350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rzi_BI9UOnM7"
      },
      "source": [
        "from keras.models import load_model\n",
        "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "l2R7mHJYOnM7"
      },
      "source": [
        "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dWVpEVhcOnM7"
      },
      "source": [
        "encoder = Model(input_signal, encoded4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "BeyAKScmOnM8"
      },
      "source": [
        "# making decoder from full autoencoder\n",
        "encoded_input = Input(shape=(2*n,))\n",
        "\n",
        "deco = autoencoder.layers[-3](encoded_input)\n",
        "deco1 = autoencoder.layers[-2](deco)\n",
        "deco2 = autoencoder.layers[-1](deco1)\n",
        "decoder = Model(encoded_input, deco2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EIH8mITYOnM8"
      },
      "source": [
        "N = 1000000\n",
        "test_label = np.random.randint(M,size=N)\n",
        "test_data = []\n",
        "\n",
        "for i in test_label:\n",
        "    temp=bin(i)[2:].zfill(k)\n",
        "    temp=np.array([float(d) for d in temp])\n",
        "    test_data.append(temp)\n",
        "    \n",
        "test_data = np.array(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfyVhHoFOnM9",
        "outputId": "2bfb6531-5ff5-45f3-8c34-dacee88477a0"
      },
      "source": [
        "temp_test = 6\n",
        "print (test_data[temp_test],test_label[temp_test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 0. 0.] 252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "p6LiK_ahOnM-"
      },
      "source": [
        "def frange(x, y, jump):\n",
        "  while x < y:\n",
        "    yield x\n",
        "    x += jump"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yoV_6ROfbxp"
      },
      "source": [
        "# BER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SdUXfCAh0xe",
        "outputId": "e828d83b-781e-46a1-e0f2-6120e8d2dd61"
      },
      "source": [
        "EbNodB_range = list(frange(0,11,1))\r\n",
        "ber = [None]*len(EbNodB_range)\r\n",
        "for i in range(0,len(EbNodB_range)):\r\n",
        "    EbNo=10.0**(EbNodB_range[i]/10.0)\r\n",
        "    noise_std = np.sqrt(1/(2*R*kmod*EbNo))\r\n",
        "    noise_mean = 0\r\n",
        "    no_errors = 0\r\n",
        "    noise = noise_std * np.random.randn(N,2*n)\r\n",
        "    encoded_signal = encoder.predict(test_data) \r\n",
        "    final_signal = encoded_signal + noise\r\n",
        "    pred_final_signal =  decoder.predict(final_signal)\r\n",
        "    \r\n",
        "    #pred_output = np.where(pred_final_signal >= 0.5 , 1, 0)\r\n",
        "    ber[i] = K.mean(K.cast(K.not_equal(test_data, K.round(pred_final_signal)),dtype='float32')).numpy()\r\n",
        "    print ('SNR:',EbNodB_range[i],'BER:',ber[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0 BER: 0.062544\n",
            "SNR: 1 BER: 0.044944376\n",
            "SNR: 2 BER: 0.0300495\n",
            "SNR: 3 BER: 0.018966125\n",
            "SNR: 4 BER: 0.010895625\n",
            "SNR: 5 BER: 0.00567525\n",
            "SNR: 6 BER: 0.002659625\n",
            "SNR: 7 BER: 0.001058125\n",
            "SNR: 8 BER: 0.0003715\n",
            "SNR: 9 BER: 0.000111875\n",
            "SNR: 10 BER: 2.6125e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJGAG2cbfWBt"
      },
      "source": [
        "### Matlab Array form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_SPVbFkOnM_",
        "outputId": "873e5484-ef86-4129-e8c1-f98aa3c72e9b"
      },
      "source": [
        "for i in range(0,len(EbNodB_range)):\r\n",
        "  print(ber[i], \" \",end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.062544  0.044944376  0.0300495  0.018966125  0.010895625  0.00567525  0.002659625  0.001058125  0.0003715  0.000111875  2.6125e-05  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7tspDRXfe1S"
      },
      "source": [
        "MER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-8Ftb6Bglzy",
        "outputId": "1b36e072-3c40-47d4-95bb-2c0447384120"
      },
      "source": [
        "EbNodB_range = list(frange(0,11,1))\r\n",
        "mer = [None]*len(EbNodB_range)\r\n",
        "for i in range(0,len(EbNodB_range)):\r\n",
        "    EbNo=10.0**(EbNodB_range[i]/10.0)\r\n",
        "    noise_std = np.sqrt(1/(2*R*kmod*EbNo))\r\n",
        "    noise_mean = 0\r\n",
        "    no_errors = 0\r\n",
        "    noise = noise_std * np.random.randn(N,2*n)\r\n",
        "    encoded_signal = encoder.predict(test_data) \r\n",
        "    final_signal = encoded_signal + noise\r\n",
        "    pred_final_signal =  decoder.predict(final_signal)\r\n",
        "    #pred_output = np.where(pred_final_signal >= 0.5 , 1, 0)\r\n",
        "    mer[i] = np.max((pred_final_signal.round()!=test_data),axis=1).mean()\r\n",
        "    print ('SNR:',EbNodB_range[i],'mER:',mer[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0 mER: 0.406486\n",
            "SNR: 1 mER: 0.306428\n",
            "SNR: 2 mER: 0.2168\n",
            "SNR: 3 mER: 0.140864\n",
            "SNR: 4 mER: 0.083349\n",
            "SNR: 5 mER: 0.044436\n",
            "SNR: 6 mER: 0.020562\n",
            "SNR: 7 mER: 0.008475\n",
            "SNR: 8 mER: 0.00304\n",
            "SNR: 9 mER: 0.000873\n",
            "SNR: 10 mER: 0.000198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqidZlSn6iK",
        "outputId": "88776785-f35a-4fee-9b61-e85b3384fd7e"
      },
      "source": [
        "for i in range(0,len(EbNodB_range)):\r\n",
        "  print(mer[i], \" \",end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.406486  0.306428  0.2168  0.140864  0.083349  0.044436  0.020562  0.008475  0.00304  0.000873  0.000198  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Lwg6h5p3Lj",
        "outputId": "85dd920d-3077-4d9c-c1cd-0eb594ab2b7e"
      },
      "source": [
        "np.max((pred_final_signal.round()!=test_data),axis=1).sum()/1000000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.4e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2StRsUc4xWcC"
      },
      "source": [
        "Block Error rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lajzDhGUybOc",
        "outputId": "6b9385cf-b761-4576-f030-98d8a5d2732d"
      },
      "source": [
        "EbNodB_range = list(frange(0,11,1))\r\n",
        "bler = [None]*len(EbNodB_range)\r\n",
        "for i in range(0,len(EbNodB_range)):\r\n",
        "    EbNo=10.0**(EbNodB_range[i]/10.0)\r\n",
        "    noise_std = np.sqrt(1/(2*R*kmod*EbNo))\r\n",
        "    noise_mean = 0\r\n",
        "    no_errors = 0\r\n",
        "    noise = noise_std * np.random.randn(N,2*n)\r\n",
        "    encoded_signal = encoder.predict(test_data) \r\n",
        "    final_signal = encoded_signal + noise\r\n",
        "    pred_final_signal =  decoder.predict(final_signal)\r\n",
        "    #pred_output = np.where(pred_final_signal >= 0.5 , 1, 0)\r\n",
        "    predicted_block=pred_final_signal.reshape(10000,800)\r\n",
        "    test_data_block=test_data.reshape(10000,800)\r\n",
        "    bler[i] = np.max((predicted_block.round()!=test_data_block),axis=1).mean()\r\n",
        "    print ('SNR:',EbNodB_range[i],'BLER:',bler[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0 BLER: 1.0\n",
            "SNR: 1 BLER: 1.0\n",
            "SNR: 2 BLER: 1.0\n",
            "SNR: 3 BLER: 1.0\n",
            "SNR: 4 BLER: 0.9999\n",
            "SNR: 5 BLER: 0.9873\n",
            "SNR: 6 BLER: 0.8781\n",
            "SNR: 7 BLER: 0.5753\n",
            "SNR: 8 BLER: 0.2557\n",
            "SNR: 9 BLER: 0.0819\n",
            "SNR: 10 BLER: 0.0184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy6cEBtz0mei",
        "outputId": "ef2385f9-f2c1-42a9-f797-ac71b62b1e31"
      },
      "source": [
        "for i in range(0,len(EbNodB_range)):\r\n",
        "  print(bler[i], \" \",end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0  1.0  1.0  1.0  0.9999  0.9873  0.8781  0.5753  0.2557  0.0819  0.0184  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JN_c-Qg2JCG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}